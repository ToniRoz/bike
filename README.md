# Bike Wheel Truing Reinforcment learning framework

Contains a RL-Environment that simulates the truing process of a spoked bycicle wheel ,as well as, different RL-algorithms to find a scalable automatic solution through training.

## General

The simulation was taken and only slightly runtime-optimized from the dissertation on bycicle-wheels from Dr. Matthew Ford.
A web-implementation, python code and information on the dissertation can be found here: [1]
There are three different Algorithms implemented in this repo: DQN (mostly with all the Rainbow improvements)[2], PPO[3] and TD-MPC2[4]


## Algorithm Implementation

### DQN (Rainbow)

Was originally taken from this implementation[5]

### PPO

Was originally taken from this implementation[6]

### TDMPC2

Was originally taken from this implementation[7]

## Usage


## References
[1] [Matthew Ford Github](https://github.com/dashdotrobot)
[2][Rainbow Paper](https://arxiv.org/abs/1710.02298)
[3][PPO Paper](https://arxiv.org/abs/1707.06347)
[4][TDMPC2](https://www.tdmpc2.com/)
[5][Rainbow Git](https://github.com/Kaixhin/Rainbow)
[6][PPO implementation](https://github.com/saqib1707/RL-PPO-PyTorch)
[7][TDMPC2 implementation](https://github.com/ShaneFlandermeyer/tdmpc2-jax)
